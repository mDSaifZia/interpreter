import argparse
import ast
from custom_semantic_checker import SemanticChecker
from custom_lexer import Lexer
from custom_parser import Parser
from custom_bytecode_generator import BytecodeGenerator

#To run this file from proj dir: 
# python FrontEndParts/frontend_manager.py -i testing/inputSourceCodeFiles/sourceCode.rtsk

def readBytecodeFile(filepath):
    with open(filepath, "rb") as f:
        header = f.read(64)
        funcdef_start = int.from_bytes(header[0:8], byteorder='little')
        funcdef_end = int.from_bytes(header[8:16], byteorder='little')
        classdef_start = int.from_bytes(header[16:24], byteorder='little')
        classdef_end = int.from_bytes(header[24:32], byteorder='little')
        mainexec_start = int.from_bytes(header[32:40], byteorder='little')
        
        print("\n===================== Header =====================")
        print(f"Function start: {funcdef_start}")
        print(f"Function end: {funcdef_end}")
        print(f"Class start: {classdef_start}")
        print(f"Class end: {classdef_end}")
        print(f"Main execution start: {mainexec_start}")
        
        # Compute main execution code size
        main_code_size = funcdef_start - 64
        main_code_bytes = f.read(main_code_size)
        main_code = main_code_bytes.decode("utf-8")
        print("\n===================== Main Exec =====================")
        print(main_code)
        
        # func defs
        func_defs_bytes = f.read()
        func_defs = func_defs_bytes.decode("utf-8")
        print("\n===================== Function Def =====================")
        print(func_defs)

def lexical_analysis(source_code):
    lexer = Lexer(source_code)
    tokens = lexer.tokenize()   # produces a list of Token objects
    print("Tokens:")
    for token in tokens:
        print(token)
    return tokens

def syntax_analysis(tokens):
    parser_obj = Parser(tokens) 
    ast = parser_obj.parse()    # produces an Abstract Syntax Tree (AST) from the list of Token objects
    print("\nAST:")
    print(ast)
    return ast

def semantic_analysis(ast):
    checker = SemanticChecker()
    try:
        checker.check(ast)
        print("Semantic Analysis: PASS")
    except Exception as e:
        print(f"Semantic Analysis: FAIL ({e})")

def generate_bytecode(ast, output_file):
    generator = BytecodeGenerator()
    generator.write_bytecode(ast, output_file)

# ================================================ Main ================================================
def main():
    parser_arg = argparse.ArgumentParser(description="Custom Language Compiler")
    parser_arg.add_argument("-i", "--input", required=True, help="Input source code file (.rtsk)")
    # parser_arg.add_argument("-o", "--output", required=True, help="Output bytecode file")
    args = parser_arg.parse_args()

    inputfileName = args.input.split('/')[-1].split('.')[0]  # get the file name without extension
    output_file = f"testing/outputByteCodeFiles/main{inputfileName[-1]}.bytecode"

    # Read the source code from the input file.
    with open(args.input, 'r') as f:
        code = f.read()

    tokens = lexical_analysis(code) # Lexical analysis

    ast = syntax_analysis(tokens)   # Syntax analysis

    semantic_analysis(ast)  # Semantic analysis

    generate_bytecode(ast, output_file) # Bytecode generation

    readBytecodeFile(output_file) # Read the generated bytecode file (For testing purposes)
    
if __name__ == '__main__':
    main()
